## Homework Assignment 2

Due Tuesday, April 13, 2021 at 9:00 am

2019314211 Minhyun Lee



### 1. Eulerian Video Magnification

This project explores **Eulerian Video Magnification** to reveal temporal image variations that tend to be difficult to visualize. (e.g., amplifying blood flow and low-amplitude motion). The primary goal of this assignment is to amplify **temporal color variations**.

#### INITIALS AND COLOR TRANSFORMATION (5 points)

In step 1, I read the video frames, preprocessed each frame, and finally got the frames converted to the YIQ color space. The result is shown below.

```matlab
%% 1. INITIALS AND COLOR TRANSFORMATION (5 PTS)
vr = VideoReader(root);
frames = read(vr);

% double-precision with range [0,1]
frames = double(frames) / 255;

% Convert each of the frames to the YIQ color space.
[H, W, C, N] = size(frames);

frames_YIQ = zeros(H, W, C, N);

for i=1:N
    frames_YIQ(:,:,:,i) = rgb2ntsc(frames(:,:,:,i));
end
```

#### Result (the first frame of face.mp4)

![1618216875271](C:\Users\lmh31\AppData\Roaming\Typora\typora-user-images\1618216875271.png)



#### LAPLACIAN PYRAMID (20 points)

In step 2, I constructed a Laplacian pyramid for every single frame in the video sequence. To obtain the **gaussian frame**, the gaussian filter is adopted using `imgaussfilt`, then down-sampled using `imresize`. To get the **residual frame**, the down-sampled frame is up-sampled. This process is performed recursively. The result is also shown below.

```matlab
%% 2. LAPLACIAN PYRAMID (20 PTS)

function [ gaussian_frames, residual_frames ] = construct_laplacian_pyramid(frames, gaussian_std)
    [H, W, C, N] = size(frames);
    gaussian_frames = zeros(floor((H+1)/2), floor((W+1)/2), C, N);
    residual_frames = zeros(H, W, C, N);

    for i=1:N
        ori_frame = frames(:,:,:,i);
        % gaussian
        gaussian_frame = imgaussfilt(ori_frame, gaussian_std);
        % downsampling
        downsampled_frame = imresize(gaussian_frame, 0.5);
        % upsampling
        upsampled_frame = imresize(downsampled_frame, [H, W]);
        % compute residual
        residual_frame = ori_frame - upsampled_frame;

        gaussian_frames(:,:,:,i) = downsampled_frame;
        residual_frames(:,:,:,i) = residual_frame;
    end
end

% construct laplacian pyramid for each level
[gau_frames_1, res_frames_0] = construct_laplacian_pyramid(frames_YIQ, gaussian_std);
[gau_frames_2, res_frames_1] = construct_laplacian_pyramid(gau_frames_1, gaussian_std);
[gau_frames_3, res_frames_2] = construct_laplacian_pyramid(gau_frames_2, gaussian_std);
[gau_frames_4, res_frames_3] = construct_laplacian_pyramid(gau_frames_3, gaussian_std);
```

#### Result	

![1618217691704](C:\Users\lmh31\AppData\Roaming\Typora\typora-user-images\1618217691704.png)



#### TEMPORAL FILTERING (30 points) & EXTRACTING THE FREQUENCY BAND OF INTEREST (30 points)

In step 3&4, I did **temporal filtering** and **extracting the frequency band of interest**. For temporal filtering, firstly, the video frames is transformed to frequency domain using `fft`. Then, in frequency domain, the bandpass filter should be applied to extract the frequency band of interest. For bandpass filter, I used the `butterworthBandpassFilter` with the parameters in the given [paper](http://people.csail.mit.edu/mrub/papers/vidmag.pdf). I visualized the histogram of frequency responses for the *face.mp4*. As shown in the below figure, it can be seen that the **frequency of band of interest** from the `butterworthBandpassFilter` with the given parameter and the **peak point of the *face.mp4*** frames are somewhat **similar**. So, using the filter, I can extract the frequency band of interest and amplify the signals.

```matlab
%% 3. TEMPORAL FILTERING (30 PTS) & 4. EXTRACTING THE FREQUENCY BAND OF INTEREST (30 PTS)
function [ filtered_frames ] = temporal_filtering( Hd, frames, alpha, level )
    [H, W, C, N] = size(frames);
    fftHd = freqz(Hd, N+1);
    % zero padding for FFT
    zero_padding_l = 2*N;
    temp_frames = zeros(H, W, C, zero_padding_l);

    fftHd_zp = zeros(zero_padding_l, 1);
    fftHd_zp(1:N+1) = fftHd;
    fftHd_zp(N+2:end) = fftHd(N:-1:2);

    temp = zeros(N, 1);
    
    for c=2:C
        for w=1:W
            for h=1:H
                temp(:, 1) = frames(h,w,c,:);
                % FFT
                fft_temp = fft(temp, zero_padding_l, 1);
                % filtering process, inverse FFT, and amplification
                temp_frames(h,w,c,:) = alpha .* ...
                    real(ifft(fft_temp .* fftHd_zp, zero_padding_l, 1));
            end
        end
    end

    filtered_frames = temp_frames(:,:,:,1:N);

end

fps = vr.FrameRate;
Hd = butterworthBandpassFilter(fps, 256, omega_l, omega_h);

filtered_gau_frames_4 = temporal_filtering(Hd, gau_frames_4, alpha, 5);
filtered_res_frames_3 = temporal_filtering(Hd, res_frames_3, alpha, 4);
filtered_res_frames_2 = temporal_filtering(Hd, res_frames_2, alpha, 3);
filtered_res_frames_1 = temporal_filtering(Hd, res_frames_1, alpha, 2);
filtered_res_frames_0 = temporal_filtering(Hd, res_frames_0, alpha, 1);
```

#### Result (face.mp4)

#### ![1618217832695](C:\Users\lmh31\AppData\Roaming\Typora\typora-user-images\1618217832695.png)

#### IMAGE RECONSTRUCTION (20 points)

In step 5, I reconstructed the Laplacian pyramids into a single image per frame from the filtered video frames. After reconstruction, the amplified image frames are added to the original frames. At this time, to enhance the temporal color variation, the addition was performed on the **I** and **Q** channels.

```matlab
%% 5. IMAGE RECONSTRUCTION (20 PTS, WHICH INCLUDES EVALUATION OF YOUR RESULTS)

function [ upsampled_laplacian ] = upsample_laplacian( frames, res_frames )
    [H, W, C, N] = size(res_frames);
    % upsampling and adding with residual frames
    upsampled_laplacian = imresize(frames, [H, W]) + res_frames;
end

% reconstruction process
re_frames_3 = upsample_laplacian(filtered_gau_frames_4, filtered_res_frames_3);
re_frames_2 = upsample_laplacian(re_frames_3, filtered_res_frames_2);
re_frames_1 = upsample_laplacian(re_frames_2, filtered_res_frames_1);
re_frames_0 = upsample_laplacian(re_frames_1, filtered_res_frames_0);

re_frames_0(:,:,2,:) = re_frames_0(:,:,2,:);
re_frames_0(:,:,3,:) = re_frames_0(:,:,3,:);

re_frames = re_frames_0 + frames_YIQ;

frames_RGB = zeros(H, W, C, N, 'uint8');

for i=1:N
    frame = ntsc2rgb(re_frames(:,:,:,i));
    frame = frame * 255.;
    frame(frame > 255.) = 255;
    frame(frame < 0. ) = 0;
    frame = uint8(frame);
    
    frames_RGB(:,:,:,i) = frame;
end

vw = VideoWriter(save_path);
open(vw);

for i=1:N
    writeVideo(vw, squeeze(frames_RGB(:, :, :, i)));
end

close(vw);
```

#### Result

![](C:\Users\lmh31\Downloads\A2 (1)\P2\output\face.gif)



![](C:\Users\lmh31\Downloads\A2 (1)\P2\output\baby2.gif)



#### EXTRA CREDIT: CAPTURE AND MOTION-MAGNIFY YOUR OWN VIDEO(S) (up to 30 points)

For this step, I captured **my own video sequences**. The below figure shows the histogram of frequency responses of my own video. As shown in the figure, I observed that the the **frequency band of interest** has the range **0.8-1.2Hz**. When measuring the **pulse rate**, a value of **67 bpm** was observed, which corresponds to **1.12 Hz**. Then, I amplified the signals using the `butterworthBandpassFilter`. The results are shown below.

#### ![](C:\Users\lmh31\Downloads\A2 (1)\P2\figure\myvideo\plot_fft.jpg)

![](C:\Users\lmh31\Downloads\A2 (1)\P2\output\myvideo.gif)